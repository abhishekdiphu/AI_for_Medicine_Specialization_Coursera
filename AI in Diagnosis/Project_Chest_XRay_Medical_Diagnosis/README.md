# Chest X-Ray Medical Diagnosis with Deep Learning

- Pre-process and prepare a real-world X-ray dataset
- Use transfer learning to retrain a DenseNet model for X-ray image classification
- Learn a technique to handle class imbalance
- Measure diagnostic performance by computing the AUC (Area Under the Curve) for the ROC - (Receiver Operating Characteristic) curve
- Visualize model activity using GradCAMs


## 1.Pre-Processing : 


## 2.Model training :

#### loss function
- weighted binary cross entropy.

$$\mathcal{L}_{cross-entropy}(x_i) = -(y_i \log(f(x_i)) + (1-y_i) \log(1-f(x_i))),$$


## 3.Evaluation tools :


#### Accuacy
(true positives+true negatives)/(true positives+true negatives+false positives+false negatives) 

#### ROC :

Prediction of 0.5 and above should be treated as positive and otherwise it should be treated as negative. This however was a rather arbitrary choice. One way to see this, is to look at a very informative visualization called the receiver operating characteristic (ROC) curve.

The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. The ideal point is at the top left, with a true positive rate of 1 and a false positive rate of 0. The various points on the curve are generated by gradually changing the threshold.

The area under the ROC curve is also called AUCROC or C-statistic and is a measure of goodness of fit. In medical literature this number also gives the probability that a randomly selected patient who experienced a condition had a higher risk score than a patient who had not experienced the event. This summarizes the model output across all thresholds, and provides a good sense of the discriminative power of a given model.


#### Sensitivity:
- P(predicted_positive | actual_positive)
- TP/(TP + FN)
- Sensitivity only considers output on people in the positive class

#### Specificity (recall):

- P(predicted_negative | actual_negative)
- TN/(TN + FP)
-  specificity only considers output on people in the negative class.

#### conditional probability:

bayes rule:
P(A|B) = [P(B|A)* P(A)] / [P(B)]

#### PPV (Precision):
- P(actual_postive | predicted_postive) 
or 
by bayes rules ,

= P(predicted_postive | actual_postive )*P(actual_postive)/P(predicted_positive)
- Positive predictive value (PPV) is the probability that subjects with a positive screening test truly have the disease.
- TP/ TP + FP

#### NPV:

- Negative predictive value (NPV) is the probability that subjects with a negative screening test truly don't have the disease.
- P(actual_neg | predicted_neg)
or 
by bayes rule ,

= P(predicted_neg | actual_neg) *P(actual_neg)/P(predicted_neg)
- TN/(TN + FN)

#### Confusion matrix:
TP FN
FP TN

true positive (TP): The model classifies the example as positive, and the actual label also positive.
false positive (FP): The model classifies the example as positive, but the actual label is negative.
true negative (TN): The model classifies the example as negative, and the actual label is also negative.
false negative (FN): The model classifies the example as negative, but the label is actually positive.

- To compute binary class predictions, we need to convert these to either 0 or 1.
We'll do this using a threshold value  th .
- Any model outputs above  th  are set to 1, and below  th  are set to 0.

#### Calculating PPV in terms of sensitivity, specificity:
- sensitivity * prevalence /(sensitivity*prevelence + (1- sensitivity)*(1- prevelence))) 

#### Prevalence

In a medical context, prevalence is the proportion of people in the population who have the disease (or condition, etc).
In machine learning terms, this is the proportion of positive examples. The expression for prevalence is:

prevalence=1Nâˆ‘iyi




## 4.Explainable-AI (model explanation)

#### Gradcam:

- they belong to the class of class-activation maps. they are called , gradient-class-activation map.
- usually used for interpreting which part of the features in an image does it contributes to the predicted class of the image.
- Since early layers deals with low level features , and last layers deals with high level features , so the last convolutional layer is being taken for this purpose.(knwn as spatial maps).
- these maps are usually smaller than the input images , between 7x7xk to 14x14xk , depending on the architectures of CNN.
- now , if there are k activation maps A1 TO Ak , then , first calulate average weight for all the activation maps , by taking partitial derivates , of output score 'y' for a particular class with respect to each feature Aij of the activation map A.
- with the help of these , activation map weights ,  we calculate the localization map from these activation maps (A1, A2.....AK).
- We apply the relu(0,max) on the weighted sum of the all k activation maps(A) to get only the postive influence and discard the negative incluence to obtain the the localization maps.
- trasnlate the localization map to heatmap  by a colormap . it is the same shap as the activation map.
- then resize  the heatmap to the size  of  the input image though interpolation technique.
- overlay the heatmap onto  the  input image with some transparency.
